{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ce93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dascore as dc\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import slice_das_segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad58ad2",
   "metadata": {},
   "source": [
    "# Demo: slice_das_segment Function\n",
    "\n",
    "This notebook demonstrates the usage of the `slice_das_segment` function from `utils.py`. This function extracts DAS (Distributed Acoustic Sensing) data segments within a specified time range by automatically finding and concatenating the appropriate files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b255da",
   "metadata": {},
   "source": [
    "## Function Overview\n",
    "\n",
    "**Function Signature:**\n",
    "```python\n",
    "slice_das_segment(start_time, end_time, source_dir)\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `start_time` (str): Start time in format \"YYYYMMDDTHHMMSS\" \n",
    "- `end_time` (str): End time in format \"YYYYMMDDTHHMMSS\"\n",
    "- `source_dir` (str): Directory containing DAS HDF5 files\n",
    "\n",
    "**Returns:**\n",
    "- `dascore.Patch`: A DAS data segment containing recordings within the specified time range\n",
    "\n",
    "**Key Features:**\n",
    "- Automatically finds files that overlap with the time range\n",
    "- Concatenates multiple files if the time range spans across files\n",
    "- Handles temporal slicing to extract exact time windows\n",
    "- Uses binary search for efficient file selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f0e88",
   "metadata": {},
   "source": [
    "## Tips and Best Practices\n",
    "\n",
    "### **Usage Tips:**\n",
    "\n",
    "1. **Time Format**: Always use the format \"YYYYMMDDTHHMMSS\" for start_time and end_time\n",
    "2. **File Naming**: Ensure your DAS files follow the naming convention: `16B_StrainRate_YYYYMMDDTHHMMSS+0000_NNNNN.h5`\n",
    "3. **Directory Structure**: Organize files in a single directory for optimal performance\n",
    "\n",
    "### **Important Considerations:**\n",
    "\n",
    "1. **Memory Usage**: Large time ranges will load more data into memory\n",
    "2. **File Boundaries**: The function handles file concatenation automatically\n",
    "3. **Time Zones**: Make sure your time stamps are in the same timezone as the file naming convention\n",
    "4. **Error Handling**: Always wrap function calls in try-except blocks for robust code\n",
    "\n",
    "### **Related Functions:**\n",
    "\n",
    "- `timestamp2datetime()`: Convert string timestamps to datetime objects\n",
    "- `timestampFromFilename()`: Extract timestamps from DAS filenames\n",
    "- `binary_search_first_extreme()`: Efficiently find files in time ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bcba9e",
   "metadata": {},
   "source": [
    "# Example 1: Single File Time Range\n",
    "This example demonstrates how a window of <12s is selected from a directory of DAS files. The function selects the appropriate file based on its name, and then cuts the signal to include only the samples from the given range (start_time, end_time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic Usage\n",
    "# Define the source directory containing DAS files\n",
    "source_dir = \"/Users/danilodordevic/Desktop/Code/FORGE_bigstar/validation_data_traget\"\n",
    "\n",
    "# Define time range for extraction\n",
    "# Format: \"YYYYMMDDTHHMMSS\"\n",
    "start_time = \"20240407T000040\"  # April 7, 2024, 00:00:40\n",
    "end_time = \"20240407T000042\"    # April 7, 2024, 00:00:42\n",
    "\n",
    "print(f\"Extracting DAS data from {start_time} to {end_time}\")\n",
    "print(f\"Source directory: {source_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the slice_das_segment function\n",
    "try:\n",
    "    # Extract the DAS segment\n",
    "    das_patch = slice_das_segment(start_time, end_time, source_dir)\n",
    "    das_patch = das_patch.transpose('distance', 'time')\n",
    "    \n",
    "    print(\"Successfully extracted DAS segment!\")\n",
    "    print(f\"Patch shape: {das_patch.shape}\")\n",
    "    print(f\"Time range: {das_patch.coords.get_array('time').min()} to {das_patch.coords.get_array('time').max()}\")\n",
    "    print(f\"Number of channels: {len(das_patch.coords.get_array('distance'))}\")\n",
    "    print(f\"Sampling rate: {1/(das_patch.attrs.coords['time'].step / np.timedelta64(1, 's'))} Hz\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ERROR: Source directory not found - {e}\")\n",
    "    print(\"Please update the source_dir path to point to your DAS data directory\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR extracting DAS segment: {e}\")\n",
    "    print(\"This might occur if no files exist in the specified time range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f2a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have a valid DAS patch to visualize\n",
    "if 'das_patch' in locals() and das_patch is not None:\n",
    "    try:\n",
    "        # Create a single plot for waterfall\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(15, 6))\n",
    "        \n",
    "        # Plot: Waterfall plot using dascore\n",
    "        das_patch.viz.waterfall(ax=ax1, scale=0.001)\n",
    "        ax1.set_title(\"DAS Waterfall Plot\")\n",
    "        ax1.set_xlabel(\"Time\")\n",
    "        ax1.set_ylabel(\"Channel/Distance\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Plotted DAS data with shape: {das_patch.data.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR creating visualization: {e}\")\n",
    "else:\n",
    "    print(\"ERROR: No DAS patch available for visualization. Please run the extraction cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f7e8a",
   "metadata": {},
   "source": [
    "## Example 2: Cross-File Time Range\n",
    "\n",
    "This example demonstrates how `slice_das_segment` handles time ranges that span across multiple files. The function automatically identifies all relevant files, concatenates them, and cuts only the relevant segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Extract data spanning multiple files\n",
    "# This demonstrates how the function handles concatenation\n",
    "\n",
    "# Define a longer time range that likely spans multiple files\n",
    "start_time_long = \"20240407T000040\"\n",
    "end_time_long = \"20240407T000140\"    # 1-minute window\n",
    "\n",
    "print(f\"Extracting longer DAS segment from {start_time_long} to {end_time_long}\")\n",
    "print(\"This time range likely spans multiple HDF5 files...\")\n",
    "\n",
    "try:\n",
    "    # Extract the longer DAS segment\n",
    "    das_patch_long = slice_das_segment(start_time_long, end_time_long, source_dir)\n",
    "    das_patch_long = das_patch_long.transpose('distance', 'time')\n",
    "    \n",
    "    print(\"Successfully extracted multi-file DAS segment!\")\n",
    "    print(f\"Patch shape: {das_patch_long.shape}\")\n",
    "    print(f\"Time range: {das_patch_long.coords.get_array('time').min()} to {das_patch.coords.get_array('time').max()}\")\n",
    "    print(f\"Number of channels: {len(das_patch_long.coords.get_array('distance'))}\")\n",
    "    print(f\"Sampling rate: {1/(das_patch_long.attrs.coords['time'].step / np.timedelta64(1, 's'))} Hz\")\n",
    "\n",
    "    # Calculate approximate number of files used\n",
    "    typical_file_duration = 12  # seconds (approximate)\n",
    "    total_duration = (das_patch_long.coords['time'].max() - das_patch_long.coords['time'].min())/1e9\n",
    "    estimated_files = int(total_duration / typical_file_duration) + 1\n",
    "    print(f\"Files concatenated: ~{estimated_files}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "    print(\"This might occur if the source directory path is incorrect or files are missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5acf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have a valid DAS patch to visualize\n",
    "if 'das_patch_long' in locals() and das_patch_long is not None:\n",
    "    try:\n",
    "        # Create a single plot for waterfall\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(15, 6))\n",
    "        \n",
    "        # Plot: Waterfall plot using dascore\n",
    "        das_patch_long.viz.waterfall(ax=ax1, scale=0.001)\n",
    "        ax1.set_title(\"DAS Waterfall Plot\")\n",
    "        ax1.set_xlabel(\"Time\")\n",
    "        ax1.set_ylabel(\"Channel/Distance\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Plotted DAS data with shape: {das_patch_long.data.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR creating visualization: {e}\")\n",
    "else:\n",
    "    print(\"ERROR: No DAS patch available for visualization. Please run the extraction cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645cecb",
   "metadata": {},
   "source": [
    "## Example 3: Practical Usage with File Discovery\n",
    "\n",
    "This example shows how to discover available files and choose appropriate time ranges, and their format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Discover available files and time ranges\n",
    "from utils import timestamp2datetime, timestampFromFilename\n",
    "\n",
    "# For demo purposes, use a local directory that might exist\n",
    "# Update this path to match your local setup\n",
    "demo_source_dir = \"/Users/danilodordevic/Desktop/Code/FORGE_bigstar/validation_data_traget\"  # Fallback to current directory\n",
    "\n",
    "# Function to discover available DAS files\n",
    "def discover_das_files(directory):\n",
    "    \"\"\"Discover and analyze available DAS files in a directory.\"\"\"\n",
    "    try:\n",
    "        files = [f for f in os.listdir(directory) if f.endswith('.h5') and f.startswith('16B')]\n",
    "        if not files:\n",
    "            print(f\"ERROR: No DAS files found in {directory}\")\n",
    "            return []\n",
    "        \n",
    "        # Sort files by timestamp\n",
    "        files_with_time = []\n",
    "        for f in files:\n",
    "            try:\n",
    "                timestamp = timestampFromFilename(f)\n",
    "                dt = timestamp2datetime(timestamp)\n",
    "                files_with_time.append((f, dt, timestamp))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        files_with_time.sort(key=lambda x: x[1])\n",
    "        return files_with_time\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Directory not found: {directory}\")\n",
    "        return []\n",
    "\n",
    "# Discover files\n",
    "print(f\"Discovering DAS files in: {demo_source_dir}\")\n",
    "available_files = discover_das_files(demo_source_dir)\n",
    "\n",
    "if available_files:\n",
    "    print(f\"SUCCESS: Found {len(available_files)} DAS files\")\n",
    "    print(\"First 5 files:\")\n",
    "    for i, (filename, dt, timestamp) in enumerate(available_files[:5]):\n",
    "        print(f\"  {i+1}. {filename}\")\n",
    "        print(f\"     Time: {dt} (timestamp: {timestamp})\")\n",
    "    \n",
    "    print(f\"\\nTime range available:\")\n",
    "    print(f\"  Start: {available_files[0][1]} ({available_files[0][2]})\")\n",
    "    print(f\"  End:   {available_files[-1][1]} ({available_files[-1][2]})\")\n",
    "else:\n",
    "    print(\"No files available for demonstration.\")\n",
    "    print(\"To run this demo with real data:\")\n",
    "    print(\"1. Update 'demo_source_dir' to point to your DAS data directory\")\n",
    "    print(\"2. Ensure the directory contains files matching pattern: 16B_StrainRate_*.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
