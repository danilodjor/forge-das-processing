{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.signal import decimate\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import h5py\n",
    "from scipy.signal import resample_poly, decimate, resample\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup source and target folders\n",
    "source_dir = \"/scratch/ddordevic/FORGE/downsample_test_source\"\n",
    "target_dir = \"/scratch/ddordevic/FORGE/downsample_test_target\"\n",
    "\n",
    "os.makedirs(target_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp2datetime(timestamp):\n",
    "    return datetime.strptime(timestamp, \"%Y%m%dT%H%M%S\")\n",
    "\n",
    "def timestampFromFilename(filename):\n",
    "    return filename.split(\"StrainRate_\")[1].split(\"+\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through files, take 3 consecutive files, merge them and downsample\n",
    "\n",
    "def process_files(source_dir, target_dir):\n",
    "    # Sort the filenames according to the date\n",
    "    files = [f for f in os.listdir(source_dir) if f.endswith('.h5') and f.startswith('16B')]\n",
    "    files = sorted(files, key=lambda f: timestampFromFilename(f))\n",
    "\n",
    "    # Process first file\n",
    "    file1_path = os.path.join(source_dir, files[0])\n",
    "    file2_path = os.path.join(source_dir, files[1])\n",
    "\n",
    "    file1_path_new = os.path.join(target_dir, files[0])\n",
    "    shutil.copy2(file1_path, file1_path_new)\n",
    "\n",
    "    f1 = h5py.File(file1_path_new, 'r+')\n",
    "    f2 = h5py.File(file2_path, 'r')\n",
    "\n",
    "    dataset1 = f1['Acoustic']\n",
    "    dataset2 = f2['Acoustic']\n",
    "\n",
    "    datasets_data = np.concatenate([dataset1, dataset2], axis=0)\n",
    "    data_downsampled = resample(datasets_data, num=datasets_data.shape[0]//2, axis=0) # resample_poly(datasets_data, up=1, down=2, axis=0)\n",
    "    data_downsampled = data_downsampled[:dataset1.shape[0]//2]\n",
    "\n",
    "    assert data_downsampled.shape[0] == dataset1.shape[0]//2 and data_downsampled.shape[1] == dataset1.shape[1]\n",
    "\n",
    "    dataset1.resize(data_downsampled.shape)\n",
    "    dataset1[...] = data_downsampled\n",
    "    dataset1.attrs.modify('TimeSamplingInterval(seconds)', dataset1.attrs['TimeSamplingInterval(seconds)']*2)\n",
    "    dataset1.attrs.modify('InterrogationRate(Hz)', dataset1.attrs['InterrogationRate(Hz)']/2)\n",
    "\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "\n",
    "    # Process triplets of consecutive files\n",
    "    for i in tqdm(range(1, len(files)-1), desc=\"Downsampling files:\"):\n",
    "        file1_path = os.path.join(source_dir, files[i-1])\n",
    "        file2_path = os.path.join(source_dir, files[i]) # main file to process\n",
    "        file3_path = os.path.join(source_dir, files[i+1])\n",
    "\n",
    "        file2_path_new = os.path.join(target_dir, files[i])\n",
    "        shutil.copy2(file2_path, file2_path_new)\n",
    "\n",
    "        f1 = h5py.File(file1_path, 'r')\n",
    "        f2 = h5py.File(file2_path_new, 'r+')\n",
    "        f3 = h5py.File(file3_path, 'r')\n",
    "\n",
    "        dataset1 = f1['Acoustic']\n",
    "        dataset2 = f2['Acoustic']\n",
    "        dataset3 = f3['Acoustic']\n",
    "\n",
    "        datasets_data = np.concatenate([dataset1, dataset2, dataset3], axis=0)\n",
    "        data_downsampled = resample(datasets_data, num=datasets_data.shape[0]//2, axis=0) # resample_poly(datasets_data, up=1, down=2, axis=0)\n",
    "        data_downsampled = data_downsampled[dataset1.shape[0]//2:dataset1.shape[0]//2+dataset2.shape[0]//2]\n",
    "\n",
    "        assert data_downsampled.shape[0] == dataset2.shape[0]//2 and data_downsampled.shape[1] == dataset2.shape[1]\n",
    "\n",
    "        dataset2.resize(data_downsampled.shape)\n",
    "        dataset2[...] = data_downsampled\n",
    "        dataset2.attrs.modify('TimeSamplingInterval(seconds)', dataset2.attrs['TimeSamplingInterval(seconds)']*2)\n",
    "        dataset2.attrs.modify('InterrogationRate(Hz)', dataset2.attrs['InterrogationRate(Hz)']/2) \n",
    "\n",
    "        f1.close()\n",
    "        f2.close()\n",
    "        f3.close()\n",
    "\n",
    "        os.remove(file1_path)\n",
    "\n",
    "    # Process last file\n",
    "    file1_path = os.path.join(source_dir, files[-2])\n",
    "    file2_path = os.path.join(source_dir, files[-1])\n",
    "\n",
    "    file2_path_new = os.path.join(target_dir, files[-1])\n",
    "    shutil.copy2(file2_path, file2_path_new)\n",
    "\n",
    "    f1 = h5py.File(file1_path, 'r')\n",
    "    f2 = h5py.File(file2_path_new, 'r+')\n",
    "\n",
    "    dataset1 = f1['Acoustic']\n",
    "    dataset2 = f2['Acoustic']\n",
    "\n",
    "    datasets_data = np.concatenate([dataset1, dataset2], axis=0)\n",
    "    data_downsampled = resample(datasets_data, num=datasets_data.shape[0]//2, axis=0) # resample_poly(datasets_data, up=1, down=2, axis=0)\n",
    "    data_downsampled = data_downsampled[dataset1.shape[0]//2:dataset1.shape[0]//2+dataset2.shape[0]]\n",
    "\n",
    "    assert data_downsampled.shape[0] == dataset2.shape[0]//2 and data_downsampled.shape[1] == dataset2.shape[1]\n",
    "\n",
    "    dataset2.resize(data_downsampled.shape)\n",
    "    dataset2[...] = data_downsampled\n",
    "    dataset2.attrs.modify('TimeSamplingInterval(seconds)', dataset2.attrs['TimeSamplingInterval(seconds)']*2)\n",
    "    dataset2.attrs.modify('InterrogationRate(Hz)', dataset2.attrs['InterrogationRate(Hz)']/2)\n",
    "\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "\n",
    "    os.remove(file1_path)\n",
    "    os.remove(file2_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downsampling files:: 100%|██████████| 3/3 [00:51<00:00, 17.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# Test run\n",
    "process_files(source_dir, target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data in the two files is the same.\n"
     ]
    }
   ],
   "source": [
    "# Validation of results\n",
    "def compare_files(file1_path, file2_path):\n",
    "    with h5py.File(file1_path, 'r') as f1, h5py.File(file2_path, 'r') as f2:\n",
    "        dataset1 = f1['Acoustic']\n",
    "        dataset2 = f2['Acoustic']\n",
    "        \n",
    "        data1 = dataset1[...]\n",
    "        data2 = dataset2[...]\n",
    "        \n",
    "        if np.array_equal(data1, data2):\n",
    "            print(\"The data in the two files is the same.\")\n",
    "        else:\n",
    "            print(\"The data in the two files is different.\")\n",
    "\n",
    "# Example usage\n",
    "file1_path = \"/scratch/ddordevic/FORGE/example_data/16B_StrainRate_20240407T072128+0000_34573_method2.h5\"\n",
    "file2_path = \"/scratch/ddordevic/FORGE/downsample_test_target/16B_StrainRate_20240407T072128+0000_34573.h5\"\n",
    "compare_files(file1_path, file2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 1496)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(\"/scratch/ddordevic/FORGE/validation_data/16B_1_StrainRate_20240421T214608+0000_32.h5\", 'r') as f:\n",
    "    d1 = f['Acoustic']\n",
    "    print(d1[...].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dascore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
